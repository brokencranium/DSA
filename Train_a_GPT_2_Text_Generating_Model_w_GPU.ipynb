{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train a GPT-2 Text-Generating Model w/ GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brokencranium/DSA/blob/master/Train_a_GPT_2_Text_Generating_Model_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: May 5th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "outputId": "b675b21f-2ded-4569-a0d1-f19611f70b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install -q gpt_2_simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE",
        "colab_type": "text"
      },
      "source": [
        "## Verify GPU\n",
        "\n",
        "Colaboratory now uses an Nvidia T4 GPU, which is slightly faster than the old Nvidia K80 GPU for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text. However sometimes the K80 will still be used.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab_type": "code",
        "outputId": "7cd1a2e0-c37c-46c2-a689-0693f8e881ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  5 16:40:56 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    75W / 149W |   8339MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are two sizes of GPT-2:\n",
        "\n",
        "* `117M` (default): the \"small\" model, 500MB on disk.\n",
        "* `345M`: the \"medium\" model, 1.5GB on disk.\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "outputId": "36e44794-7b11-4aad-f529-36bd67c3571d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"117M\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 319kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 53.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 503kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:06, 75.6Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 1.74Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 42.1Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 40.9Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"shakespeare.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "a0cffe5f-568b-452b-a09b-fdd221d22312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10971
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='117M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 338025 tokens\n",
            "Training...\n",
            "[10 | 29.42] loss=3.66 avg=3.66\n",
            "[20 | 53.33] loss=3.83 avg=3.75\n",
            "[30 | 76.63] loss=3.48 avg=3.66\n",
            "[40 | 99.91] loss=3.23 avg=3.55\n",
            "[50 | 123.47] loss=3.50 avg=3.54\n",
            "[60 | 147.03] loss=3.42 avg=3.52\n",
            "[70 | 170.45] loss=3.28 avg=3.48\n",
            "[80 | 193.86] loss=3.08 avg=3.43\n",
            "[90 | 217.36] loss=3.29 avg=3.41\n",
            "[100 | 240.86] loss=3.26 avg=3.40\n",
            "[110 | 264.33] loss=3.02 avg=3.36\n",
            "[120 | 287.79] loss=2.96 avg=3.33\n",
            "[130 | 311.23] loss=3.01 avg=3.30\n",
            "[140 | 334.68] loss=3.08 avg=3.28\n",
            "[150 | 358.10] loss=2.80 avg=3.25\n",
            "[160 | 381.53] loss=3.03 avg=3.23\n",
            "[170 | 404.94] loss=2.95 avg=3.22\n",
            "[180 | 428.36] loss=3.10 avg=3.21\n",
            "[190 | 451.82] loss=2.83 avg=3.19\n",
            "[200 | 475.25] loss=2.86 avg=3.17\n",
            "======== SAMPLE 1 ========\n",
            " no of them that I mean nor any they seem: they are all ungentles; they are all noisier, being noisier: they are all but a strange kind of sensual pleasure.\n",
            "\n",
            "PRINCE:\n",
            "So that, having these thoughts I take them as I have made the best and most perfect,\n",
            "These will be my thoughts, and their happiness they will be\n",
            "The perfection of good.\n",
            "Now they are all I, they all being but as I am,\n",
            "I should desire them. They must not be lost in your minds;\n",
            "For they are but but very dreams, the worst and most false,\n",
            "As in the dream of the creature, if I did see it come,\n",
            "And the dream of God.\n",
            "I cannot but dream; I mean as a dream, God come,\n",
            "Which is as the very thing it is, but less.\n",
            "This will not I, which is as it are, but as a dream:\n",
            "Or else God come, which I dream too, but more.\n",
            "\n",
            "PRINCE:\n",
            "O, God, this is too much for your liking, and too little\n",
            "For seeing what God would do with words.\n",
            "\n",
            "ARCHISETES:\n",
            "No, but as for being in a dream,\n",
            "God come, God come, God come! This is a world\n",
            "That makes the same sound to your ears, when it is dream'd.\n",
            "\n",
            "PRINCE:\n",
            "If a world were too much, the gods would laugh their hearts\n",
            "With words, but as no thing in the world\n",
            "Can have meaning to them, so too is the world\n",
            "That sounds nothing but a world and not that.\n",
            "Therefore it behoves you not to give thoughts reason to do\n",
            "Thou mad: rather, use them in so doing,\n",
            "For this to make them feel in them what you wish\n",
            "Of the things you do not mean,\n",
            "Or else they will think you good; for no meaning's there\n",
            "Tills their hearts that do think no meaning.\n",
            "\n",
            "ARCHISETES:\n",
            "\n",
            "PRINCE:\n",
            "You speak not what you mean, and are not sensible to what\n",
            "You mean.\n",
            "\n",
            "ARCHISETES:\n",
            "\n",
            "PRINCE:\n",
            "What's the matter, you talk of wanting meaning?\n",
            "\n",
            "ARCHISETES:\n",
            "\n",
            "PRInce,\n",
            "You mean nothing as wanting meaning is.\n",
            "\n",
            "ARCHISETES:\n",
            "\n",
            "PRInce?\n",
            "I am sorry, very sorry, that any man can say\n",
            "This, 'My life's a dream, I wish this;' 'My life's a dream, I wish it\n",
            "A thing, it's a thing now,' that says something,\n",
            "My life's a dream, I wish this;'' so 'I wish my life am not a fool,\n",
            "And be a fool too; 'I wish it is an impossible fool!\n",
            "I am sorry, but I am sorry: let me see\n",
            "The world I want, and see for what I mean.\n",
            "A pity, but the world I want, is not an impossible dream\n",
            "To think as I see it, unless,\n",
            "If the thing else, I mean of an uncertain sense;\n",
            "If, when I see it, or believe it no more,\n",
            "I believe it not, I see no reason to lie\n",
            "A sort of contradiction in it, or of any falsehood\n",
            "Even within my senses.\n",
            "Then I can't be an impossible thing, which is in such\n",
            "It is, I can't. What I mean then is't impossible, which\n",
            "I never saw. For what I thought possible, what\n",
            "I thought possible is impossible, to be impossible\n",
            "To believe it could not be; but being so,\n",
            "It does not exist. Therefore I cannot be an impossible\n",
            "Or impossible thing, which was impossible to think.\n",
            "\n",
            "CORIOLANUS:\n",
            "I have long thought that, if there were no father and no mother,\n",
            "No father and no mother, there would be no god, not\n",
            "For all the time of our creation; but there are none.\n",
            "\n",
            "CORIOLANUS:\n",
            "Why, then I mean no god or no god, man or woman,\n",
            "No matter how much my mind may change me, how\n",
            "I will be a good man, woman or man.\n",
            "\n",
            "CORIOLANUS:\n",
            "A good and not a bad man, woman or man.\n",
            "\n",
            "CORIOLANUS:\n",
            "No more than 'twas a great good, and man is\n",
            "No better than a fool and a fooler.\n",
            "\n",
            "CORIOLANUS:\n",
            "'Sorrow in those names is nothing but sorrowing\n",
            "And all-laid down in words, and in speech means\n",
            "An't that is too dull to say; nor words which mean,\n",
            "A thing to say but in itself, no sense;\n",
            "Nor in words a sense; nor indeed in\n",
            "\n",
            "[210 | 510.33] loss=3.02 avg=3.16\n",
            "[220 | 533.78] loss=3.00 avg=3.15\n",
            "[230 | 557.26] loss=2.75 avg=3.13\n",
            "[240 | 580.71] loss=2.64 avg=3.11\n",
            "[250 | 604.16] loss=2.87 avg=3.10\n",
            "[260 | 627.61] loss=2.89 avg=3.09\n",
            "[270 | 651.07] loss=2.69 avg=3.07\n",
            "[280 | 674.52] loss=2.76 avg=3.06\n",
            "[290 | 697.98] loss=2.35 avg=3.03\n",
            "[300 | 721.45] loss=2.46 avg=3.01\n",
            "[310 | 744.94] loss=2.52 avg=2.99\n",
            "[320 | 768.46] loss=2.41 avg=2.97\n",
            "[330 | 791.96] loss=2.56 avg=2.96\n",
            "[340 | 815.45] loss=2.35 avg=2.94\n",
            "[350 | 838.95] loss=2.33 avg=2.92\n",
            "[360 | 862.45] loss=2.23 avg=2.89\n",
            "[370 | 885.96] loss=2.70 avg=2.89\n",
            "[380 | 909.46] loss=2.20 avg=2.86\n",
            "[390 | 932.99] loss=1.96 avg=2.84\n",
            "[400 | 956.49] loss=1.98 avg=2.81\n",
            "======== SAMPLE 1 ========\n",
            " reputation with her;\n",
            "She is but young to be the mistress of this\n",
            "Tidiness: and this she makes myself\n",
            "The lady whose love was ripest from me,\n",
            "Before I would have a wife: my heart is grown to\n",
            "This, it is true; here, and now, in this cell,\n",
            "To whom all this day I have call'd you for\n",
            "I pray you; if you can do your duty,\n",
            "I will kiss your heart: and for your good me,\n",
            "To make this kindness good my mistress,\n",
            "You must, my good lady, make love of me.\n",
            "\n",
            "SIR STEPHEN SCROOP:\n",
            "\n",
            "DERBY:\n",
            "What is the matter?\n",
            "\n",
            "CORRIDOR:\n",
            "What, is my father coming by?\n",
            "\n",
            "SIR STEPHEN SCROOP:\n",
            "Come, come, I pray you, sir, what news you convey'd?\n",
            "\n",
            "CORRIDOR:\n",
            "O, let me have news as soon as I can trust,\n",
            "For God's sake, there's no news of this kind at hand.\n",
            "\n",
            "SIR STEPHEN SCROOP:\n",
            "You do not love; do you not care for?\n",
            "\n",
            "CORRIDOR:\n",
            "Not a whit\n",
            "SIR STEPHEN SCROOP:\n",
            "How, in the morning the warrant was given,\n",
            "And you are still there late, in the villain house\n",
            "Where there is not a whit of food for the night,\n",
            "There is not a hair of sleep in my life\n",
            "Per half a mile abroad in the earth:\n",
            "In the house of Verona, you have a steward.\n",
            "\n",
            "CORRIDOR:\n",
            "Pardon, sir, pardon.\n",
            "Your father is on the way, my friends:\n",
            "I am in the town, to be married in Baptista's.\n",
            "\n",
            "SAMPSON:\n",
            "God bless you all, good my lord, both good\n",
            "And true! what is the matter with you, and\n",
            "what are the news?\n",
            "\n",
            "CORRIDOR:\n",
            "I know the law, sir, all rightly my part be;\n",
            "I know the order and the purpose of it,\n",
            "And how the deputy to the recorder\n",
            "Kills the man whom he accuses, that it were\n",
            "Not my fault but your father's, to have me dead:\n",
            "God save the lord mayor! the mayor\n",
            "Of Baptista is dead, and the recorder\n",
            "Kills the man whom he accuses: so if you think me\n",
            "True, your father's death proves it not.\n",
            "\n",
            "SAMPSON:\n",
            "So, the matter is laid on you, which I learn you\n",
            "By Baptista's hand, and not your reason's.\n",
            "\n",
            "CORRIDOR:\n",
            "Ay, my good lord,\n",
            "And since this news came from me, and I could\n",
            "Not to-day deny it,\n",
            "O, tell't my father but that his fault\n",
            "Is not my fault too, but that my reason\n",
            "Kills him the more, to have the man kill me.\n",
            "\n",
            "SAMPSON:\n",
            "How now, sir,\n",
            "What hath the mayor done? why is it that he?\n",
            "\n",
            "CORRIDOR:\n",
            "Is Baptista dead?\n",
            "\n",
            "SAMPSON:\n",
            "Why, then his name is mayor of Baptista.\n",
            "\n",
            "CORRIDOR:\n",
            "\n",
            "SAMPSON:\n",
            "And yet the man he murders, that had his name,\n",
            "Whom Baptista himself makes the mayor, by his son?\n",
            "\n",
            "CORRIDOR:\n",
            "Yes, my good lord: Baptista was murdered.\n",
            "\n",
            "SAMPSON:\n",
            "The man, sir; who is my brother?\n",
            "\n",
            "CORRIDOR:\n",
            "No, your good lord: but that you do me pity,\n",
            "That I do make it known to you, with my hand,\n",
            "That you are the murderer and not your brother;\n",
            "The man is dead; Baptista is mayor of\n",
            "Baptista. Murderer, my poor man; and the mayor, my\n",
            "good lord,--\n",
            "\n",
            "CORRIDOR:\n",
            "Ay.\n",
            "\n",
            "SAMPSON:\n",
            "Then, good my lord, I will confess Baptista was your\n",
            "boyster,--the bastard child of a\n",
            "great master of the state that you know my true.\n",
            "\n",
            "CORRIDOR:\n",
            "I confess, sir; you met that Baptista at his\n",
            "churchyard: and, I think, you broke to touch him,\n",
            "and, as you parted company, took leave of him,\n",
            "with your high resolution gone.\n",
            "\n",
            "CORRIDOR:\n",
            "Then, good my lord,--\n",
            "\n",
            "SAMPSON:\n",
            "Ay, to wash away blood that you must leave with your\n",
            "boy: for Baptista is out of all reason gone,\n",
            "that you shall never have these daughters there.\n",
            "\n",
            "CORRIDOR:\n",
            "O, not a sin so deep: you\n",
            "\n",
            "[410 | 990.44] loss=2.08 avg=2.79\n",
            "[420 | 1013.90] loss=1.80 avg=2.76\n",
            "[430 | 1037.44] loss=2.17 avg=2.74\n",
            "[440 | 1060.99] loss=2.08 avg=2.73\n",
            "[450 | 1084.54] loss=2.30 avg=2.71\n",
            "[460 | 1108.03] loss=2.26 avg=2.70\n",
            "[470 | 1131.51] loss=2.10 avg=2.69\n",
            "[480 | 1155.02] loss=1.88 avg=2.66\n",
            "[490 | 1178.52] loss=2.32 avg=2.66\n",
            "[500 | 1202.00] loss=2.07 avg=2.64\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 1229.34] loss=2.05 avg=2.63\n",
            "[520 | 1252.96] loss=1.91 avg=2.61\n",
            "[530 | 1276.46] loss=1.65 avg=2.59\n",
            "[540 | 1299.90] loss=2.02 avg=2.57\n",
            "[550 | 1323.36] loss=1.74 avg=2.55\n",
            "[560 | 1346.86] loss=1.49 avg=2.53\n",
            "[570 | 1370.41] loss=1.36 avg=2.50\n",
            "[580 | 1393.94] loss=1.84 avg=2.49\n",
            "[590 | 1417.51] loss=1.45 avg=2.46\n",
            "[600 | 1441.00] loss=1.01 avg=2.43\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "\n",
            "MERCUTIO:\n",
            "It is a very foul creature,\n",
            "That tempts me to look into it; but every drop\n",
            "Still stains my path.\n",
            "\n",
            "LEONTES:\n",
            "It is a very foul thing,\n",
            "That flies upon my eye: yet nature\n",
            "Centleles me to give it rest.\n",
            "\n",
            "PAGE:\n",
            "\n",
            "LEONTES:\n",
            "It moves her, but she cannot hear\n",
            "It.\n",
            "\n",
            "PAGE:\n",
            "\n",
            "LEONTES:\n",
            "Thou dost make me mad;\n",
            "I am not like to help, nor am I careless\n",
            "To look back and learn of thy meaning.\n",
            "I will make thee uneasy, and thou my foe,\n",
            "Else in my heart should fear thee match'd.\n",
            "\n",
            "LEONTES:\n",
            "This is my will, and thou shalt be witness.\n",
            "I will be king, and I will defend thee,\n",
            "If Hercules serve me well.\n",
            "Go, levy for haste, and prepare: here!\n",
            "Welcome, our day-tossing soldiers, to the field;\n",
            "The foe's no more: but I'll revenge, I say.\n",
            "Away, I say, and with no boot!\n",
            "\n",
            "VIRGILIA:\n",
            "We came to her from the field, where we mount'd,\n",
            "To see her battle; and she was soon join'd\n",
            "With us, though she in that sense be termed slave:\n",
            "She was not she had arrived; therefore, be it,\n",
            "She left us, and we'll deal with her that join'd;\n",
            "For now, I hope, she hath agreed with us.\n",
            "\n",
            "LEONTES:\n",
            "'Tis honour, and not courtesy, which makes her\n",
            "Apparely join'd with us in our tent:\n",
            "Away! I say, and with no boot!\n",
            "\n",
            "POLIXENES:\n",
            "Welcome, my lords, to your tent; the day\n",
            "Of welcome is the eve of judgment:\n",
            "Horus the rex serpents forth!\n",
            "\n",
            "First Lord:\n",
            "Now had I know it was Hercules, they were,\n",
            "In face to face, brethren of the queen,\n",
            "That coined this match, this battle;\n",
            "But to the queen's heavy charge, I long have;\n",
            "For I have heard it quash'd their cats;\n",
            "And therefore have I here announce it to you,\n",
            "And you, my lords, here follow me:\n",
            "Go you to my tent; where, lords, we will quietly mingle\n",
            "My verdicts, and resolve doubts. Now I kneel;\n",
            "As if that eyes of heaven which badges\n",
            "The glorious naked gleam of glory with mortal light\n",
            "Refusing dimly by vain reply should,\n",
            "Are full of faith and duty now invested\n",
            "With no less than the firm obedience of nature,\n",
            "That from false devotion does atticken truth,\n",
            "And in that truth atticken darkness.\n",
            "What if these false pretences of this tender earth--\n",
            "Where true devotion vainly seeks,\n",
            "When it perceives that the deceit pursues\n",
            "The mighty unity of its part--\n",
            "Lead to the tents, as they had done,\n",
            "The sacred ministers which they have here prepared\n",
            "Against the hostile sun,\n",
            "To make the solemn festival of incense\n",
            "And incense: all tents brought good news,\n",
            "As if this ground had the fiery fuel it needs\n",
            "To quench the fiery ireful fang of ireful flame.\n",
            "But wherefore the camp, and not near?\n",
            "\n",
            "First Lord:\n",
            "In these reasons why we stand ready,\n",
            "We may well perceive their true meaning;\n",
            "And if we fear not our foxes, if\n",
            "Our fang any, why shall we vex them\n",
            "Where it pleaseth us to do good?\n",
            "\n",
            "Page:\n",
            "Horus the rex serpents forth!\n",
            "\n",
            "LEONTES:\n",
            "This is their herald: 'tis our will,\n",
            "If they consent to join with us,\n",
            "To fight with us either in the field\n",
            "Or in close fight on the shore.\n",
            "\n",
            "Page:\n",
            "We, the Host, have ta'en you in heart\n",
            "For fight with brother Aufidius.\n",
            "\n",
            "LEONTES:\n",
            "O, he was Aufidius' friend!\n",
            "\n",
            "Page:\n",
            "That he is worthily armed, even though he hunt,\n",
            "Or I am afraid, I judge, as you\n",
            "Tight bleeding on either side; and, in their\n",
            "defiance, they hunt as fast as we\n",
            "Carry'd the commonalty of liberty.\n",
            "\n",
            "Page:\n",
            "'Tis well; and think't\n",
            "You'll see Aufidius in a torch-bearer.\n",
            "\n",
            "LEONTES:\n",
            "I have seen him at Aufidius' monument,\n",
            "And have kill'd him with my lance: or if you\n",
            "Have not, I have the gage of his looks, if\n",
            "your man have pity'd us.\n",
            "\n",
            "[610 | 1474.92] loss=1.67 avg=2.41\n",
            "[620 | 1498.37] loss=1.60 avg=2.40\n",
            "[630 | 1521.84] loss=1.66 avg=2.38\n",
            "[640 | 1545.38] loss=1.42 avg=2.36\n",
            "[650 | 1568.93] loss=1.30 avg=2.34\n",
            "[660 | 1592.46] loss=1.43 avg=2.32\n",
            "[670 | 1615.95] loss=1.11 avg=2.29\n",
            "[680 | 1639.45] loss=0.90 avg=2.27\n",
            "[690 | 1662.96] loss=1.01 avg=2.24\n",
            "[700 | 1686.46] loss=0.99 avg=2.22\n",
            "[710 | 1709.97] loss=1.37 avg=2.20\n",
            "[720 | 1733.47] loss=1.16 avg=2.18\n",
            "[730 | 1756.94] loss=1.15 avg=2.16\n",
            "[740 | 1780.44] loss=0.96 avg=2.14\n",
            "[750 | 1803.91] loss=0.76 avg=2.11\n",
            "[760 | 1827.38] loss=0.84 avg=2.09\n",
            "[770 | 1850.84] loss=0.72 avg=2.06\n",
            "[780 | 1874.32] loss=1.10 avg=2.04\n",
            "[790 | 1897.78] loss=0.84 avg=2.02\n",
            "[800 | 1921.24] loss=0.84 avg=2.00\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "RICHARD:\n",
            "Your grace has leave to go: but I will walk fast.\n",
            "\n",
            "ANGELO:\n",
            "I do love her, and I'll marry her: go,\n",
            "Speak to her privately.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Now, afore God\n",
            "A divine act! Was ever scholar so swift,\n",
            "As he that long abide in his bosom,\n",
            "Write eloquent verses on his face?\n",
            "Is plain speech all that? Go, understand;\n",
            "Speak, plain sentence: for this is no scripture,\n",
            "Let rich and poor be read in their proper time,\n",
            "Let both be agreed upon, and brook bless!\n",
            "\n",
            "RICHARD:\n",
            "Read not this sentence, lest you be sentenced to sleep:\n",
            "It is no sin, prince, but it fits your judgment,\n",
            "And your pleasure is not to be so perverse;\n",
            "It is a piece of virtuous chivalry:\n",
            "Do no more: you may say it is a tall tale,\n",
            "But it fits the piece you are jocund upon.\n",
            "\n",
            "ANGELO:\n",
            "It fits the piece I am jolly fond of;\n",
            "And it fits the piece I am best pleased\n",
            "To glide by the brave Earl of Gaunt.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Relate this left to me. It fits the piece as well\n",
            "As any I have pronounced on him and he me:\n",
            "Let it be read with skill and skill not scorn:\n",
            "This is a slanderous sentence: remonstrantly\n",
            "It cannot be made but by Clarence and against him.\n",
            "\n",
            "RICHARD:\n",
            "Clarence's sentence is as far in the law as\n",
            "will excuse the wearing of the words,\n",
            "Wheby the king hath in hand: mine is as far\n",
            "I can urge it. Take him from him, and tie him up;\n",
            "Let him be your accuser, and try whether\n",
            "Clarence doth or calleth the other way.\n",
            "\n",
            "ANGELO:\n",
            "Clarence doth it not? O no, no; no, it gavings.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Clarence says he doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence says he doth; he doth it not.\n",
            "\n",
            "ANGELO:\n",
            "Clarence says he doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence says he doth; he doth it not.\n",
            "\n",
            "RICHARD:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "ANGELO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "RICHARD:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "ANGELO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "RICHARD:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "ANGELO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "RICHARD:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "ANGELO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "CLAUDIO:\n",
            "Clarence doth; he doth it not.\n",
            "\n",
            "LEONTES:\n",
            "Where is the common tongue?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The king; where is the common tongue to lay\n",
            "Our guilt.\n",
            "\n",
            "LEONTES:\n",
            "How dost thou slander it?\n",
            "\n",
            "LEONTES:\n",
            "The common tongue is common strength.\n",
            "\n",
            "CLAUDIO:\n",
            "How dost thou slander it?\n",
            "\n",
            "LEONTES:\n",
            "Gloucester for Gloucester: he should be ashamed\n",
            "Whereof the king belongs.\n",
            "\n",
            "CLAUDIO:\n",
            "Then have at thy sight. Go in: be frank;\n",
            "We are the more eminent for our tongue.\n",
            "\n",
            "ANGELO:\n",
            "This deed is more than halibut.\n",
            "\n",
            "LEONTES:\n",
            "Let me embrace him.\n",
            "\n",
            "CLAUDIO:\n",
            "Let me embrace him.\n",
            "\n",
            "LEONTES:\n",
            "Let him that is incapable\n",
            "Become all extirp\n",
            "\n",
            "[810 | 1955.24] loss=0.75 avg=1.98\n",
            "[820 | 1978.68] loss=1.27 avg=1.97\n",
            "[830 | 2002.13] loss=0.85 avg=1.95\n",
            "[840 | 2025.58] loss=0.48 avg=1.92\n",
            "[850 | 2049.06] loss=0.80 avg=1.90\n",
            "[860 | 2072.53] loss=0.71 avg=1.88\n",
            "[870 | 2096.00] loss=0.82 avg=1.86\n",
            "[880 | 2119.47] loss=0.42 avg=1.84\n",
            "[890 | 2142.97] loss=0.49 avg=1.81\n",
            "[900 | 2166.43] loss=0.40 avg=1.79\n",
            "[910 | 2189.93] loss=0.42 avg=1.77\n",
            "[920 | 2213.47] loss=0.91 avg=1.75\n",
            "[930 | 2237.01] loss=0.99 avg=1.74\n",
            "[940 | 2260.55] loss=0.33 avg=1.72\n",
            "[950 | 2284.07] loss=0.48 avg=1.70\n",
            "[960 | 2307.66] loss=0.31 avg=1.68\n",
            "[970 | 2331.19] loss=0.34 avg=1.65\n",
            "[980 | 2354.69] loss=0.67 avg=1.64\n",
            "[990 | 2378.22] loss=0.53 avg=1.62\n",
            "[1000 | 2401.71] loss=0.25 avg=1.60\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. (NB: if you are downloading the model to your personal computer, download the large model checkpoint file *seperately*, download the other files, and reconstruct the `/checkpoint/run1` folder hierarchy locally)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `checkpoint` folder from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "outputId": "0e11dcf7-fbb0-43a7-db4c-a8333f27b8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2176
        }
      },
      "source": [
        "gpt2.generate(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have sat here all day\n",
            "Unto this hand, as if it\n",
            "Did some thing nigh me, whoo!\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "What hand?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "My uncle Clarence' greatest kindness.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "My liege, I had rather lie in wait on thee.\n",
            "I promised thy duke should come and apprehend\n",
            "Thy wife and young daughter.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "What, do you mean, to apprehend my daughter?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "To answer the duke.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, what then? 'tis time thou hadst come.\n",
            "Uncle, you have made a sainted father of you.\n",
            "Dare you break your fast before the king's seal\n",
            "And besiege the buried foes with a holy vow?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Why, how now, uncle! hast thou forsook thy wife\n",
            "For divines; for she's the mother of all\n",
            "Abstinence; that she may enter\n",
            "Of these most holy nuns?\n",
            "Or blasphemers, perjured liars, and true\n",
            "Of Christ so manifest?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Have you forsook your wife\n",
            "For any of these liars; for few,\n",
            "When they shall come to speak for them, but they\n",
            "Must heartily confess themselves true.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Why, what, have I left her?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Uncle, you have made good work; but she's changed\n",
            "And is no more hereafter to grace the air\n",
            "Than thou hast ever been a girl.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Uncle, thou hast made good supper; but I am\n",
            "Disgusted with thee. Go not home.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, fie, fie, fie! Why, fie, fie!\n",
            "Thou hast made me requite my former hours of nap,\n",
            "In ordering the day, of all; fie, fie!\n",
            "Thou hast put on my gown, which I have untied up,\n",
            "With a little hoop; and, not to be seen,\n",
            "I have got a pair of bloody shoes,\n",
            "In thine own part, with bloody palms.\n",
            "Fie, fie! fie, fie! I am tired, fie!\n",
            "I have done enough; I am done with thee!\n",
            "Farewell, fie! farewell; I am done.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Prithee, peace enjoin you.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "How fares my uncle Clarence?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "O dear my liege,\n",
            "How is it that thou dost depart so soon?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "With signs of thine that thou wilt not show.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, what of my general?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Are you so resolved that I am not pleased?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "No, no, my good Clarence; nor of our state.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, so?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, then, am I resolved that thou hast\n",
            "Misgave me my due and wronged me; and that\n",
            "Thou hast plotted against me with devilish plots\n",
            "To raze my treasure and take my daughter from me.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Why, so.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Then know you for truth that I have\n",
            "Infer'd my daughter from thee? and thou hast plotted\n",
            "Against me with devilish plots to raze\n",
            "My treasure and take from me a daughter?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "With what malice didst thou first betray\n",
            "My dear son Mowbray? and then did\n",
            "Thou wrong my dear wife and daughter?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, then know you for truth that I am\n",
            "In earnest peril; and, knowing my meaning,\n",
            "Have plotted against me with devilish plots\n",
            "To raze my treasure and take from me\n",
            "A daughter; and having laid thee on the high ground,\n",
            "Have drawn thy sword more than ever sword of truth.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "I have drawn it,\n",
            "Or sought it; and, if thou slay me,\n",
            "I'll give thee life as quickly as I can.\n",
            "And tell how this ends, that the last\n",
            "Doth not live to\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "outputId": "ec1fc622-c3fe-43e5-9312-f26cec6e52fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3679
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LORD FITZWATER:\n",
            "Saw'st thou not, sir?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Madam, didst thou not mean, as some do,\n",
            "To cram others with beggary?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Ha, ha! what should you say? why didst thou say no?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Hath this woman in this world hungrier than man?\n",
            "Think'st thou that all these woes can be avoided?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "As many lives she hath prevented as man.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Why, hark! the Tower is brought down.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "The King of Naples comes apace.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "It shall be so, I hope.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "The Tower comes down.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "The Naples comes apace.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "It shall be so, I hope.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "\n",
            "====================\n",
            "\n",
            "LORDY:\n",
            "Every man that's gone hath died\n",
            "And that's the end of all.\n",
            "\n",
            "GLOUCESTER:\n",
            "Your lordship must be revenged, Hermione.\n",
            "\n",
            "LADY ANNE:\n",
            "And she shall be the man that I dreamt of.\n",
            "\n",
            "GLOUCESTER:\n",
            "I cannot sleep: never a waking man shall\n",
            "Go to any sleepder than to sleep.\n",
            "\n",
            "LADY ANNE:\n",
            "It shall be such a dream, I'll bear witness to it,\n",
            "That I may believe what I say.\n",
            "\n",
            "GLOUCESTER:\n",
            "All tongues to hell: never man to man,\n",
            "Let light hear me?\n",
            "\n",
            "LADY ANNE:\n",
            "No, I'll not bear witness to it.\n",
            "\n",
            "GLOUCESTER:\n",
            "I said you had heard it, but could not put\n",
            "You in words.\n",
            "\n",
            "LADY ANNE:\n",
            "It is a strange tale, the tale doth it:\n",
            "Hermione's great care is felling on wild Bolingbroke,\n",
            "And Bolingbroke is the king.\n",
            "\n",
            "GLOUCESTER:\n",
            "I could not put mine hand\n",
            "====================\n",
            "\n",
            "LORD FITZWATER:\n",
            "On pain of death, will he live to see this day\n",
            "His country requite itself again.\n",
            "\n",
            "DUKE OF YORK:\n",
            "What country?\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Nor none but himself,\n",
            "That is, most certainly, from this day on\n",
            "My proudest unknown man shall be your king.\n",
            "\n",
            "DUKE OF AUMERLE:\n",
            "Of all men I am the one who shall lose.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Take thou the crown, and crown it well\n",
            "With all the proudest that have touch'd it.\n",
            "\n",
            "DUKE OF YORK:\n",
            "I'll have the crown too, and set it on me.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Now York shall stand for his wish.\n",
            "\n",
            "DUKE OF YORK:\n",
            "Stand you like a leader, like a great king\n",
            "And will you yield all obedience to him?\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "I'll be king, I vow thee.\n",
            "\n",
            "DUKE OF YORK:\n",
            "And shall stand for that aim so well\n",
            "In all\n",
            "====================\n",
            "\n",
            "LORD FITZWATER:\n",
            "Sir, your company is witness to that.\n",
            "\n",
            "Servant:\n",
            "The duke shall have a chamber-maid,\n",
            "And not an officer of the people, to take\n",
            "The absolute duke of his city.\n",
            "\n",
            "GLOUCESTER:\n",
            "That's as many rogues as there are.\n",
            "\n",
            "Servant:\n",
            "Nine!\n",
            "\n",
            "Servant:\n",
            "Nine rogues!\n",
            "\n",
            "Servant:\n",
            "Nine!\n",
            "\n",
            "GLOUCESTER:\n",
            "A foul witch! Undone, go with her:\n",
            "This jade shall be queen of the dead.\n",
            "\n",
            "Servant:\n",
            "I'll not be queen.\n",
            "\n",
            "Servant:\n",
            "By any other name\n",
            "Will destroy Richard's crown,\n",
            "And London enter in a new sense.\n",
            "\n",
            "Lord:\n",
            "What is the king's name?\n",
            "\n",
            "Lord:\n",
            "Richard's name; 'tis the name of the duke slain\n",
            "In your famous battle.\n",
            "\n",
            "Servant:\n",
            "Nine!\n",
            "\n",
            "Lord:\n",
            "Nine!\n",
            "\n",
            "Servant:\n",
            "Nine!\n",
            "\n",
            "GLOUCESTER:\n",
            "The king!\n",
            "\n",
            "Servant:\n",
            "Nine!\n",
            "\n",
            "Lord:\n",
            "\n",
            "====================\n",
            "\n",
            "LORD STANLEY:\n",
            "Away with her!\n",
            "\n",
            "CATESBY:\n",
            "What counsel pluck, you, or me, or any of your party?\n",
            "\n",
            "WARWICK:\n",
            "Fear me not: I'll tell her she hath made a wrong.\n",
            "\n",
            "CATESBY:\n",
            "I shall feel it, sir, when I see it.\n",
            "\n",
            "WARWICK:\n",
            "Now, how shall we avoid her?\n",
            "\n",
            "KING HENRY VI:\n",
            "By living by, I'll hate myself and my tongue,\n",
            "And never bid farewell my body.\n",
            "\n",
            "CATESBY:\n",
            "'Tis a disgrace to live by,\n",
            "And I will hate myself as well as any\n",
            "Whom fortune hath held dear dear.\n",
            "\n",
            "WARWICK:\n",
            "What is the matter, my lord?\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Get you hence, gentle queen, by way of reprieve:\n",
            "The Earl of Hereford, with all the rest of Spain,\n",
            "Staying in London till the war be done,\n",
            "And Goverrus with the rest of England,\n",
            "To prevent this loss of life.\n",
            "\n",
            "CATESBY:\n",
            "This is the business.\n",
            "\n",
            "NORTHUM\n",
            "====================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp and then download it.\n",
        "\n",
        "You can rerun the cell as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )\n",
        "\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail or out-of-memory/OOM), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E",
        "colab_type": "text"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}